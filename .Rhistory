??ToothGrowth
library(datasets)
data("ToothGrowth")
summary(ToothGrowth)
require(graphics)
coplot(len ~ dose | supp, data = ToothGrowth, panel = panel.smooth,
xlab = "ToothGrowth data: length vs dose, given type of supplement")
set.seed(1234)
lambda<-0.2
nexp<-40
nsim<-1000
data1<-matrix(rexp(nexp*nsim,lambda),nsim)
mean_t<-1/lambda
mean_s<-mean(apply(data1,1,mean))
mean_s
mean_t
sd_t<-((1/lambda)*(1/sqrt(nexp)))
sd_s<-sd(apply(data1,1,mean))
sd_t
sd_s
data1<-matrix(rexp(nexp*nsim,lambda),nsim)
mean_t<-round(1/lambda,3)
mean_s<-round(mean(apply(data1,1,mean)),3)
sd_t<-round(((1/lambda)*(1/sqrt(nexp))),3)
sd_s<-round(sd(apply(data1,1,mean)),3)
var_t<-round(sd_t^2,3)
var_s<-round(var(apply(data1,1,mean)),3)
mean_t
mean_s
sd_t
sd_s
var_t
var_s
m<-matrix(c(mean_t,mean_s,sd_t,sd_s,var_t,var_s),3,2)
m
kable(m,row.names(Mean,Standard Deviation, Variance),digits = 3)
library(knitr)
kable(m,row.names(Mean,Standard Deviation, Variance),digits = 3)
kable(m,row.names("Mean","Standard Deviation", "Variance"),digits = 3)
library(ggplot2)
row_mean<-apply(data1,1,mean)
row_df<-data.frame(row_mean)
g<-ggplot(row_df,aes(x=row_mean))+
geom_histogram(binwidth = lambda,fill="violetred9",color="black")
g
g
g<-ggplot(row_df,aes(x=row_mean))+
geom_histogram(binwidth = lambda,fill="violetred",color="black")
g
g<-ggplot(row_df,aes(x=row_mean))+
geom_histogram(binwidth = lambda,fill="violetred",color="black",aex(y=..density..)
g
g<-ggplot(row_df,aes(x=row_mean))+
geom_histogram(binwidth=lambda,fill="violetred",color="black",aex(y=..density..))+
labs(title="Simulation of 40 exponential distribution",x="Mean",y="Density")+
geom_vline(xintercept=mean_s,size=1.0,color="black")+
stat_function(fun=dnorm,args=list(mean=mean_s,sd=sd_s),color="blue",size=1.0)+
geom_vline(xintercept=mean_t,size=1.0,color="red")+
stat_function(fun=dnorm,args=list(mean=mean_t,sd=sd_t),color="yellow",size=1.0)
g<-ggplot(row_df,aes(x=row_mean))+
geom_histogram(binwidth=lambda,fill="violetred",color="black",aes(y=..density..))+
labs(title="Simulation of 40 exponential distribution",x="Mean",y="Density")+
geom_vline(xintercept=mean_s,size=1.0,color="black")+
stat_function(fun=dnorm,args=list(mean=mean_s,sd=sd_s),color="blue",size=1.0)+
geom_vline(xintercept=mean_t,size=1.0,color="red")+
stat_function(fun=dnorm,args=list(mean=mean_t,sd=sd_t),color="yellow",size=1.0)
g
g<-ggplot(row_df,aes(x=row_mean))+
geom_histogram(binwidth=lambda,fill="violetred",color="black",aes(y=..density..))+
labs(title="Simulation of 40 exponential distribution",x="Mean",y="Density")+
geom_vline(xintercept=mean_s,size=1.0,color="black")+
stat_function(fun=dnorm,args=list(mean=mean_s,sd=sd_s),color="blue",size=1.0)+
geom_vline(xintercept=mean_t,size=1.0,color="red",linetype="dashed")+
stat_function(fun=dnorm,args=list(mean=mean_t,sd=sd_t),color="yellow",size=1.0)
g
colors()
g<-ggplot(mean_df,aes(x=mns))+
geom_histogram(binwidth=lambda,fill="violetred",color="black",aes(y=..density..))+
labs(title="Simulation of 40 exponential distribution",x="Mean",y="Density")+
geom_vline(xintercept=mean_s,size=1.0,color="black")+
stat_function(fun=dnorm,args=list(mean=mean_s,sd=sd_s),color="darkgreen",size=1.0)+
geom_vline(xintercept=mean_t,size=1.0,color="red",linetype="dashed")+
stat_function(fun=dnorm,args=list(mean=mean_t,sd=sd_t),color="yellow",size=1.0)
g
set.seed(1234)
lambda<-0.2
nexp<-40
mns = NULL
for (i in 1 : 1000) mns=c(mns,mean(rexp(nexp,lambda)))
mean_df<-data.frame(mns)
mean_t<-round(1/lambda,3)
mean_s<-round(mean(mean_df$mns),3)
sd_t<-round(((1/lambda)*(1/sqrt(nexp))),3)
sd_s<-round(sd(mean_df$mns),3)
var_t<-round(sd_t^2,3)
var_s<-round(var(mean_df$mns),3)
dark
g<-ggplot(mean_df,aes(x=mns))+
geom_histogram(binwidth=lambda,fill="violetred",color="black",aes(y=..density..))+
labs(title="Simulation of 40 exponential distribution",x="Mean",y="Density")+
geom_vline(xintercept=mean_s,size=1.0,color="black")+
stat_function(fun=dnorm,args=list(mean=mean_s,sd=sd_s),color="darkgreen",size=1.0)+
geom_vline(xintercept=mean_t,size=1.0,color="red",linetype="dashed")+
stat_function(fun=dnorm,args=list(mean=mean_t,sd=sd_t),color="yellow",size=1.0)
g
library(pdflatex)
install.packages("pdflatex")
g
library(pdflatex)
install.packages("pdflatex")
??pdflatex
library(datasets)
??ToothGrowth
data(ToothGrowth)
data<-ToothGrowth
head(data)
str(data)
table(data$supp,data$dose)
summary(data)
---
title: "The Effect of Vitamin C on Tooth Growth in Guinea Pigs"
output: html_document
---
##Load data / Perform basic data analysis
```{r}
library(datasets)
library(ggplot2)
data(ToothGrowth)
data<-ToothGrowth
head(data)
str(data)
table(data$supp,data$dose)
?ToothGrowth
```
###Description
The response is the length of odontoblasts (cells responsible for tooth growth) in 60 guinea pigs. Each animal received one of three dose levels of vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods, (orange juice or ascorbic acid (a form of vitamin C and coded as VC).
###Format
A data frame with 60 observations on 3 variables:
*len  (numeric) Tooth length
*supp (factor)  Supplement type (VC (ascorbic acid) or OJ (orange juice))
*dose (numeric) Dose in milligrams
##Provide a basic summary of the data
```{r}
summary(data)
ggplot(data, aes(x = supp, y = len)) +
geom_boxplot(aes(fill = supp)) +
facet_wrap(~ dose) +
ylab("Tooth Length") +
xlab("Supplement Type") +
ggtitle("Tooth Length by Supplement Type of Vitamin C (mg/day)")
```
##Confidence intervals
data
?t.test
t.test(ToothGrowth$len[ToothGrowth$dose==1.0],ToothGrowth$len[ToothGrowth$dose==0.5])
t.test(ToothGrowth$len[ToothGrowth$dose==2.0],ToothGrowth$len[ToothGrowth$dose==1.0])
t.test(ToothGrowth$len[ToothGrowth$dose==2-0],ToothGrowth$len[ToothGrowth$dose==0.5])
t.test(ToothGrowth$len[ToothGrowth$supp=="VC"],ToothGrowth$len[ToothGrowth$supp=="OJ"])
?mtcars
data(mtcars)
str(mtcars)
aut<-mtcars[mtcars$am==1,]
man<-mtcars[mtcars$am==0,]
aut_mean<-mean(aut$mpg)
aut_sd<-sd(aut$mpg)
man_mean<-mean(man$mpg)
man_sd<-sd(man$mpg)
stat<-data.frame(aut_mean,aut_sd,man_mean,man_sd)
stat
colors
colours
?colors
colors()
(t.test(man$mpg,aut$mpg,alternative="two.sided"))$p.value
model<-lm(mpg~am*wt+cyl,mtcars)
model
?mtcars
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
#Make a histogram and confirm the SuperPlasticizer variable is skewed. Normally you might use the log transform to try to make the data more symmetric. Why would that be a poor choice for this variable?
qplot(Superplasticizer, data=training)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
#Make a histogram and confirm the SuperPlasticizer variable is skewed. Normally you might use the log transform to try to make the data more symmetric. Why would that be a poor choice for this variable?
qplot(Superplasticizer, data=training)
install.packages("caret")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
#Make a histogram and confirm the SuperPlasticizer variable is skewed. Normally you might use the log transform to try to make the data more symmetric. Why would that be a poor choice for this variable?
qplot(Superplasticizer, data=training)
xnames <- colnames(concrete)[1:8]
featurePlot(x=training[, xnames], y=training$CompressiveStrength, plot="pairs")
# No relation between the outcome and other variables
index <- seq_along(1:nrow(training))
ggplot(data=training, aes(x=index, y=CompressiveStrength)) + geom_point() +
theme_bw()
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
outcome=training$diagnosis)IL <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(IL, method='pca', thresh=0.8,
outcome=training$diagnosis)
IL <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(IL, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc$rotation
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
#Find all the predictor variables in the training set that begin with IL. Perform principal components on these
#variables with the preProcess() function from the caret package. Calculate the number of principal components needed
#to capture 90% of the variance. How many are there?
IL <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(IL, method='pca', thresh=0.9,
outcome=training$diagnosis)
preProc$rotation
setwd("~/Documents/slidify")
install.packages("devtools")
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
author("Calculating_BMI")
getwd()
slidify("index.Rmd")
browseURL("index.html")
browseURL("index.html")
browseURL("index.html")
browseURL("index.html")
browseURL("index.html")
browseURL("index.html")
